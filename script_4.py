# Create requirements.txt and installation guide for artpromtAi

requirements_content = """# artpromtAi Requirements
# Core Dependencies for Text-to-Image Generation

# Deep Learning Framework
torch>=1.12.0
torchvision>=0.13.0

# Hugging Face Libraries
transformers>=4.21.0
diffusers>=0.20.0
accelerate>=0.20.0

# Streamlit Web Framework
streamlit>=1.25.0

# Image Processing
Pillow>=9.0.0
opencv-python>=4.5.0

# Tokenization
tokenizers>=0.13.0

# Scientific Computing
numpy>=1.21.0
scipy>=1.7.0

# Utilities
tqdm>=4.64.0
ftfy>=6.1.0
regex>=2022.7.9

# Optional: Fast CLIP tokenizer
# instant-clip-tokenizer>=0.1.0

# Optional: Model optimization
# safetensors>=0.3.0
# xformers>=0.0.20  # For memory optimization (requires CUDA)
"""

installation_guide = """# artpromtAi Installation Guide

## System Requirements

### Minimum Requirements:
- Python 3.8+
- 8GB RAM
- 4GB GPU VRAM (CUDA compatible)
- 50GB free disk space

### Recommended Requirements:
- Python 3.9+
- 16GB+ RAM  
- 12GB+ GPU VRAM (RTX 3080/4080, A100, etc.)
- 100GB+ free disk space
- CUDA 11.7+

## Installation Steps

### 1. Clone/Create Project Directory
```bash
mkdir artpromtai
cd artpromtai
```

### 2. Create Virtual Environment
```bash
# Using venv
python -m venv artpromtai_env
source artpromtai_env/bin/activate  # Linux/Mac
# artpromtai_env\\Scripts\\activate  # Windows

# OR using conda
conda create -n artpromtai python=3.9
conda activate artpromtai
```

### 3. Install PyTorch (GPU Version)
```bash
# For CUDA 11.7
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu117

# For CUDA 11.8  
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# For CPU only (not recommended)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Download Pre-trained Models (Optional)
Models will be automatically downloaded on first run, but you can pre-download:
```python
from diffusers import StableDiffusionPipeline
from transformers import CLIPTokenizer, CLIPTextModel

# This will download ~4-7GB of models
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id)
tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer")
```

### 6. Run the Application
```bash
streamlit run artpromtai_streamlit_app.py
```

## Troubleshooting

### Common Issues:

1. **CUDA Out of Memory**
   - Reduce image dimensions (use 512x512 instead of 1024x1024)
   - Decrease batch size/number of images
   - Enable CPU offloading

2. **Model Download Errors**
   - Check internet connection
   - Clear Hugging Face cache: `rm -rf ~/.cache/huggingface/`
   - Try different model versions

3. **Slow Generation**
   - Ensure CUDA is properly installed
   - Use GPU instead of CPU
   - Consider using xformers for optimization

### Verification Commands:
```python
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
```
"""

project_structure = """# artpromtAi Project Structure

artpromtai/
â”œâ”€â”€ artpromtai_streamlit_app.py    # Main Streamlit application
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                     # Project documentation
â”œâ”€â”€ models/                       # Model storage (auto-created)
â”‚   â”œâ”€â”€ stable-diffusion-v1-5/    # Cached model files
â”‚   â””â”€â”€ clip/                     # CLIP model cache
â”œâ”€â”€ outputs/                      # Generated images (auto-created)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ logs/
â””â”€â”€ utils/                        # Utility functions (optional)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ tokenization.py           # Text processing utilities
    â”œâ”€â”€ image_processing.py       # Image manipulation
    â””â”€â”€ model_utils.py            # Model loading helpers

## Key Files Description:

- **artpromtai_streamlit_app.py**: Main application with UI and generation logic
- **requirements.txt**: All necessary Python packages
- **models/**: Hugging Face models cached locally (~5-10GB)  
- **outputs/**: Generated images and logs
"""

# Save all files
with open('requirements.txt', 'w') as f:
    f.write(requirements_content)

with open('INSTALL.md', 'w') as f:
    f.write(installation_guide)

with open('PROJECT_STRUCTURE.md', 'w') as f:
    f.write(project_structure)

print("ðŸ“¦ Installation Package Created Successfully!")
print("\nðŸ“‹ Files Generated:")
print("  âœ“ requirements.txt - Python dependencies")
print("  âœ“ INSTALL.md - Complete installation guide") 
print("  âœ“ PROJECT_STRUCTURE.md - Project organization")
print("  âœ“ artpromtai_streamlit_app.py - Main application (from previous step)")
print("  âœ“ artpromtai_architecture.json - Project architecture")

print("\nðŸš€ Quick Start Commands:")
print("  1. pip install -r requirements.txt")
print("  2. streamlit run artpromtai_streamlit_app.py")
print("  3. Open http://localhost:8501 in your browser")

print(f"\nðŸ“Š Package Summary:")
print(f"  â€¢ Total Python packages: {len([line for line in requirements_content.split(chr(10)) if line and not line.startswith('#') and '>' in line])}")
print(f"  â€¢ Estimated download size: ~8-12GB (models + dependencies)")
print(f"  â€¢ Supported Python versions: 3.8+")
print(f"  â€¢ GPU memory requirement: 8GB+ VRAM")